{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import scipy\r\n",
    "from scipy.optimize import curve_fit"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# function for fitting with relation to T_in and T_out\r\n",
    "# x=T_in, y=T_out, z= size to fit\r\n",
    "\r\n",
    "def fit_simple(x,y,z):\r\n",
    "    p0=[0.1,0.001,1.] # starting values\r\n",
    "    a=(x,y,z) \r\n",
    "    para,_ = scipy.optimize.leastsq(func_simple_zero,p0,args=a)\r\n",
    "    return para\r\n",
    "\r\n",
    "def func_simple_zero(para, x, y, z):\r\n",
    "    k1,k2,k3 = para\r\n",
    "    z_calc = k1*x + k2*y + k3\r\n",
    "    z_diff = z_calc - z\r\n",
    "    return z_diff\r\n",
    "\r\n",
    "# Function to calculate z using parameters and any x and y:\r\n",
    "def func_simple(para, x, y):\r\n",
    "    k1,k2,k3 = para\r\n",
    "    z = k1*x + k2*y + k3\r\n",
    "    return z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Get paramters: \r\n",
    "\r\n",
    "t~450 sek"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get normalized Parameters \r\n",
    "data_key = pd.read_csv(r'output/database_keymark_average_normalized_modus_group.csv')\r\n",
    "Models=data_key['Model'].values.tolist()\r\n",
    "Models = list(dict.fromkeys(Models))#get models\r\n",
    "\r\n",
    "Group=[]\r\n",
    "Pel_n=[]\r\n",
    "Pth_max=[]\r\n",
    "k1=[]\r\n",
    "k2=[]\r\n",
    "k3=[]\r\n",
    "k4=[]\r\n",
    "k5=[]\r\n",
    "k6=[]\r\n",
    "k7=[]\r\n",
    "k8=[]\r\n",
    "k9=[]\r\n",
    "\r\n",
    "for model in Models:\r\n",
    "    data_key = pd.read_csv(r'output/database_keymark_average_normalized_modus_group.csv')\r\n",
    "    data_key = data_key.rename(columns={'P_el [W]': 'P_el', 'P_th [W]': 'P_th', 'T_in [°C]': 'T_in', 'T_out [°C]': 'T_out'})\r\n",
    "    data_key = data_key.loc[data_key['Model'] == model]#get data of model\r\n",
    "    group = data_key.Group.array[0]#get Group of model\r\n",
    "    Pel_ref=data_key.loc[data_key['P_el_n']==1,['P_el']].values.tolist()[0][0]\r\n",
    "    Pth_52=data_key.loc[data_key['T_out']==52,['P_th']].values.tolist()[0][0]\r\n",
    "    K = 273.15\r\n",
    "    eta_carnot_key = (data_key['T_out']+K) / ((data_key['T_out']+K)-(data_key['T_in']+K))\r\n",
    "    data_key['eta'] = data_key['COP'] / eta_carnot_key\r\n",
    "    data_key.fillna(0, inplace=True)\r\n",
    "    variables=['P_el_n', 'P_th_n', 'COP', 'eta']\r\n",
    "        \r\n",
    "    for var in variables: #get all parameters\r\n",
    "        vars()[var+'_para_key'] = fit_simple(data_key['T_in'],data_key['T_out'],data_key[var])\r\n",
    "        data_key[var+'_fit'] = func_simple(globals()[var+'_para_key'], data_key['T_in'], data_key['T_out'])\r\n",
    "        data_key[var+'_fit_err'] = (data_key[var+'_fit'] - data_key[var]) / data_key[var] * 100\r\n",
    "        d = data_key[var+'_fit_err'].mean(), data_key[var+'_fit_err'].max(), data_key[var+'_fit_err'].min()\r\n",
    "        vars()[var+'_err'] = pd.DataFrame(d, index=['mean', 'max', 'min'])\r\n",
    "    #write Parameters in List\r\n",
    "    k1.append(P_th_n_para_key[0])\r\n",
    "    k2.append(P_th_n_para_key[1])\r\n",
    "    k3.append(P_th_n_para_key[2])\r\n",
    "    k4.append(P_el_n_para_key[0])\r\n",
    "    k5.append(P_el_n_para_key[1])\r\n",
    "    k6.append(P_el_n_para_key[2])\r\n",
    "    k7.append(COP_para_key[0])\r\n",
    "    k8.append(COP_para_key[1])\r\n",
    "    k9.append(COP_para_key[2])\r\n",
    "    Group.append(group)\r\n",
    "    Pel_n.append(Pel_ref)\r\n",
    "    Pth_max.append(Pth_52)\r\n",
    "#write List  in Dataframe\r\n",
    "\r\n",
    "paradf=pd.DataFrame()\r\n",
    "paradf['Model']=Models\r\n",
    "paradf['k1']=k1 \r\n",
    "paradf['k2']=k2\r\n",
    "paradf['k3']=k3\r\n",
    "paradf['k4']=k4\r\n",
    "paradf['k5']=k5\r\n",
    "paradf['k6']=k6\r\n",
    "paradf['k7']=k7\r\n",
    "paradf['k8']=k8\r\n",
    "paradf['k9']=k9\r\n",
    "paradf['Group']=Group\r\n",
    "paradf['P_el_n']=Pel_n\r\n",
    "paradf['P_th_max']=Pth_max\r\n",
    "\r\n",
    "para = paradf\r\n",
    "key = pd.read_csv(r'output/database_keymark_average_normalized_modus_group.csv', delimiter=',')\r\n",
    "key=key.loc[key['T_out [°C]']==52]\r\n",
    "parakey=para.merge(key, how='left', on='Model')\r\n",
    "parakey = parakey.rename(columns={'Group_x': 'Group','P_el_n_x': 'P_el_n [W]','Prated [W]': 'Prated [kW]','P_th_max':'P_th_max [W]'})\r\n",
    "table=parakey[['Manufacturer', 'Model', 'Type', 'Modus','Refrigerant','Mass of Refrigerant [kg]','Date','SPL indoor [dBA]','SPL outdoor [dBA]','Prated [kW]','PSB [W]','Guideline','Climate','P_el_n [W]','P_th_max [W]','k1','k2','k3','k4', 'k5','k6','k7','k8','k9', 'Group']]\r\n",
    "\r\n",
    "filt1 = (table['k4'] > 0) & (table['Group']==2)\r\n",
    "table.loc[filt1, 'Group'] = 5\r\n",
    "table.loc[filt1, 'Modus'] = 'On-Off'\r\n",
    "table.to_csv('hplib.csv', encoding='utf-8', index=False)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "add Average Heatpumps:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_key = pd.read_csv('hplib.csv', delimiter=',')\r\n",
    "Power=[1000,3000,5000,10000]\r\n",
    "for levels in Power:\r\n",
    "    Groups=[1,2,4,5]\r\n",
    "    for group in Groups:\r\n",
    "        if group==1:\r\n",
    "            Type='Outdoor Air/Water'\r\n",
    "            modus='Inverter'\r\n",
    "        if group==2:\r\n",
    "            Type='Brine/Water'\r\n",
    "            modus='Inverter'\r\n",
    "        if group==4:\r\n",
    "            Type='Outdoor Air/Water'\r\n",
    "            modus='On-Off'\r\n",
    "        if group==5:\r\n",
    "            Type='Brine/Water'\r\n",
    "            modus='On-Off'\r\n",
    "        Group1=data_key.loc[data_key['Group']==group]\r\n",
    "        k1_average=Group1['k1'].mean(0)\r\n",
    "        k2_average=Group1['k2'].mean(0)\r\n",
    "        k3_average=Group1['k3'].mean(0)\r\n",
    "        k4_average=Group1['k4'].mean(0)\r\n",
    "        k5_average=Group1['k5'].mean(0)\r\n",
    "        k6_average=Group1['k6'].mean(0)\r\n",
    "        k7_average=Group1['k7'].mean(0)\r\n",
    "        k8_average=Group1['k8'].mean(0)\r\n",
    "        k9_average=Group1['k9'].mean(0)\r\n",
    "        data_key.loc[len(data_key.index)]=['average', str(levels)+'w',Type,modus,'','','','','',levels/1000,'','','average',levels,levels, k1_average,k2_average,k3_average,k4_average,k5_average,k6_average,k7_average,k8_average,k9_average,group]\r\n",
    "#data_key.drop(['Group'], axis=1,inplace=True)\r\n",
    "data_key.to_csv('data_key_para.csv', encoding='utf-8', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1c4c526e93e8287540b24b192ade22dda43c6f2790b410e79d9bb5a13eace6d2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}